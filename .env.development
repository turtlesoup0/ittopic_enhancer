# ITPE Topic Enhancement - Development Environment Configuration
# This file is used for local development with Docker Compose
#
# 보안 경고: 이 파일을 버전 관리 시스템에 커밋하지 마세요
# .gitignore에 추가되어 있어야 합니다
#
# 강력한 비밀번호 생성 방법:
# - Python: python -c "import secrets; print(secrets.token_urlsafe(16))"
# - OpenSSL: openssl rand -base64 16

# =============================================================================
# Application Settings
# =============================================================================
APP_NAME=ITPE Topic Enhancement
APP_VERSION=1.0.0
DEBUG=true

# =============================================================================
# Database (PostgreSQL for Docker Compose)
# =============================================================================
# Use PostgreSQL when running with Docker Compose
# 환경변수 참조: POSTGRES_PASSWORD를 사용하므로 직접 지정하지 마세요
DATABASE_URL=postgresql+asyncpg://itpe:${POSTGRES_PASSWORD}@postgres:5432/itpe

# PostgreSQL configuration
POSTGRES_DB=itpe
POSTGRES_USER=itpe
# 강력한 비밀번호를 사용하세요 (최소 16자, 영문/숫자/특수문자 혼합)
POSTGRES_PASSWORD=CHANGE_THIS_STRONG_PASSWORD_NOW

# =============================================================================
# Redis
# =============================================================================
# Redis connection URL with password
# 환경변수 참조: REDIS_PASSWORD를 사용하므로 직접 지정하지 마세요
REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/0

# Redis configuration
# PostgreSQL과 동일한 강력한 비밀번호를 사용하거나 별도 생성
REDIS_PASSWORD=CHANGE_THIS_STRONG_PASSWORD_NOW

# =============================================================================
# CORS (Cross-Origin Resource Sharing)
# =============================================================================
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://frontend:3000

# =============================================================================
# LLM Configuration
# =============================================================================
# OpenAI Configuration (optional)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o

# Ollama Configuration
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3.1:8b

# LLM Provider Selection: openai or ollama
LLM_PROVIDER=ollama
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=1000

# =============================================================================
# Celery Configuration
# =============================================================================
# 환경변수 참조: REDIS_PASSWORD를 사용하므로 직접 지정하지 마세요
CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/0
CELERY_RESULT_BACKEND=redis://:${REDIS_PASSWORD}@redis:6379/1

# =============================================================================
# Cache Configuration
# =============================================================================
CACHE_ENABLED=true
CACHE_BACKEND=redis
CACHE_TTL_EMBEDDING=604800
CACHE_TTL_VALIDATION=3600
CACHE_TTL_LLM=86400

# =============================================================================
# ChromaDB Configuration
# =============================================================================
CHROMADB_PATH=/app/data/chromadb
CHROMADB_COLLECTION=references

# =============================================================================
# Obsidian Configuration
# =============================================================================
# Mount your local Obsidian vault as a volume
OBSIDIAN_VAULT_PATH=/data/obsidian/vault
OBSIDIAN_EXPORT_PATH=/data/obsidian/export

# =============================================================================
# Reference Sources Configuration
# =============================================================================
# Mount your local FB21 books as a volume
FB21_BOOKS_PATH=/data/fb21-books

# =============================================================================
# Embedding Configuration
# =============================================================================
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MPNet-base-v2
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32
EMBEDDING_DIMENSION=768

# =============================================================================
# Matching Configuration
# =============================================================================
# Similarity thresholds
SIMILARITY_THRESHOLD=0.7
SIMILARITY_THRESHOLD_PDF_BOOK=0.65
SIMILARITY_THRESHOLD_BLOG=0.6
SIMILARITY_THRESHOLD_MARKDOWN=0.7
TOP_K_REFERENCES=5

# Field weights for embedding
FIELD_WEIGHT_DEFINITION=0.35
FIELD_WEIGHT_LEAD=0.25
FIELD_WEIGHT_KEYWORDS=0.25
FIELD_WEIGHT_HASHTAGS=0.10
FIELD_WEIGHT_MEMORY=0.05

# Trust score integration
TRUST_SCORE_PDF_BOOK=1.0
TRUST_SCORE_BLOG=0.8
TRUST_SCORE_MARKDOWN=0.6
TRUST_SCORE_WEIGHT=0.3
BASE_SIMILARITY_WEIGHT=0.7

# Document chunking
CHUNK_SIZE_THRESHOLD=5000
CHUNK_OVERLAP=500

# =============================================================================
# Validation Configuration
# =============================================================================
VALIDATION_RULES_PATH=/app/config/validation_rules.yaml

# =============================================================================
# Frontend Configuration
# =============================================================================
VITE_API_BASE_URL=http://localhost:8000/api/v1

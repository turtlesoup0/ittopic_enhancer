"""Integration tests for PDF-Topic matching."""
import pytest
from pathlib import Path
from app.services.matching.pdf_topic_matcher import PDFTopicMatcher


# í…ŒìŠ¤íŠ¸ìš© í† í”½ JSON ê²½ë¡œ
SAMPLE_JSON = "/Users/turtlesoup0-macmini/Documents/itpe-topic-enhancement/backend/data/topics_sample.json"

# FB21 ê¸°ë³¸ ê²½ë¡œ
FB21_PATH = "/Users/turtlesoup0-macmini/Library/CloudStorage/MYBOX-sjco1/ê³µìœ  í´ë”/ê³µìœ ë°›ì€ í´ë”/FB21ê¸° ìˆ˜ì—…ìë£Œ"


@pytest.fixture
def matcher():
    """PDFTopicMatcher fixture."""
    return PDFTopicMatcher(SAMPLE_JSON)


class TestPDFTopicMatcher:
    """PDF-í† í”½ ë§¤ì¹­ í…ŒìŠ¤íŠ¸."""

    def test_init(self, matcher):
        """ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸."""
        assert matcher.topic_service is not None
        assert matcher.pdf_parser is not None
        assert matcher.keyword_extractor is not None

    def test_detect_domain_from_filename(self, matcher):
        """íŒŒì¼ëª…ì—ì„œ ë„ë©”ì¸ ê°ì§€ í…ŒìŠ¤íŠ¸."""
        # ì‹ ê¸°ìˆ 
        domain = matcher._detect_domain("", "FB21_6ì£¼ì°¨_AI_êµì¬.pdf")
        assert domain == "ì‹ ê¸°ìˆ "

        # ì •ë³´ë³´ì•ˆ
        domain = matcher._detect_domain("", "FB21_4ì£¼ì°¨_SE_ë³´ì•ˆ.pdf")
        assert domain == "ì •ë³´ë³´ì•ˆ"

        # SW
        domain = matcher._detect_domain("", "FB21_2ì£¼ì°¨_SW_ìš”êµ¬ê³µí•™.pdf")
        assert domain == "SW"

    def test_detect_domain_from_content(self, matcher):
        """ë‚´ìš©ì—ì„œ ë„ë©”ì¸ ê°ì§€ í…ŒìŠ¤íŠ¸."""
        # AI ê´€ë ¨ ë‚´ìš©
        content = "ì¸ê³µì§€ëŠ¥ ë¨¸ì‹ ëŸ¬ë‹ ë”¥ëŸ¬ë‹ ì‹ ê²½ë§ í•™ìŠµ"
        domain = matcher._detect_domain(content, "test.pdf")
        assert domain == "ì‹ ê¸°ìˆ "

        # ë³´ì•ˆ ê´€ë ¨ ë‚´ìš©
        content = "ì •ë³´ë³´ì•ˆ ì•”í˜¸í™” í•´í‚¹ ì ‘ê·¼í†µì œ ë¹„ë°€í‚¤"
        domain = matcher._detect_domain(content, "test.pdf")
        assert domain == "ì •ë³´ë³´ì•ˆ"

    def test_extract_keywords(self, matcher):
        """í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸."""
        text = """
        ì¸ê³µì§€ëŠ¥ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì¼ì¢…ì´ë‹¤. ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•œë‹¤.
        ì •ë³´ë³´ì•ˆì€ ì•”í˜¸í™” ê¸°ìˆ ì„ ì‚¬ìš©í•œë‹¤.
        """
        keywords = matcher._extract_keywords(text)

        assert len(keywords) > 0
        # ì¤‘ìš” í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
        text_lower = " ".join(keywords).lower()
        assert "ì¸ê³µì§€ëŠ¥" in text_lower or "ë¨¸ì‹ ëŸ¬ë‹" in text_lower

    def test_extract_keywords_compound_words(self, matcher):
        """ë³µí•©ì–´ ë³´ì¡´ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸."""
        text = """
        TCP/IP í”„ë¡œí† ì½œì€ OSI 7ê³„ì¸µ ëª¨ë¸ì„ ë”°ë¥¸ë‹¤.
        REST APIëŠ” ì›¹ ì„œë¹„ìŠ¤ì—ì„œ ë„ë¦¬ ì‚¬ìš©ëœë‹¤.
        NoSQL ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë¹„ê´€ê³„í˜• ë°ì´í„° ì €ì¥ì— ì í•©í•˜ë‹¤.
        CI/CD íŒŒì´í”„ë¼ì¸ì€ DevOpsì˜ í•µì‹¬ì´ë‹¤.
        """
        keywords = matcher._extract_keywords(text)
        keyword_str = " ".join(keywords)

        # ë³µí•©ì–´ê°€ ë¶„ë¦¬ë˜ì§€ ì•Šê³  ìœ ì§€ë˜ì–´ì•¼ í•¨
        # TCP/IP í™•ì¸
        assert "TCP/IP" in keyword_str or "tcp/ip" in keyword_str

        # REST API í™•ì¸
        assert "REST API" in keyword_str or "rest api" in keyword_str or "REST" in keyword_str

        # CI/CD í™•ì¸
        assert "CI/CD" in keyword_str or "ci/cd" in keyword_str or "CI" in keyword_str

    def test_synonym_expansion_in_keywords(self, matcher):
        """ë™ì˜ì–´ í™•ì¥ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸."""
        text = """
        NW ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ë§ êµ¬ì„±ë„ë¥¼ ê²€í† í•©ë‹ˆë‹¤.
        network í† í´ë¡œì§€ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤.
        """
        keywords = matcher._extract_keywords(text)
        keyword_str = " ".join(keywords).lower()

        # ë™ì˜ì–´ í™•ì¥ìœ¼ë¡œ ì¸í•´ "ë„¤íŠ¸ì›Œí¬"ê°€ ê²°ê³¼ì— í¬í•¨ë˜ì–´ì•¼ í•¨
        # ë˜ëŠ” ì›ë³¸ ë™ì˜ì–´ ì¤‘ í•˜ë‚˜ê°€ ìˆì–´ì•¼ í•¨
        has_network = any(
            kw in keyword_str
            for kw in ["ë„¤íŠ¸ì›Œí¬", "network", "nw", "ë§"]
        )
        assert has_network

    @pytest.mark.skipif(
        not Path(FB21_PATH).exists(),
        reason="FB21 ê²½ë¡œì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ"
    )
    def test_match_real_pdf(self, matcher):
        """ì‹¤ì œ FB21 PDF ë§¤ì¹­ í…ŒìŠ¤íŠ¸."""
        # FB21 ê²½ë¡œì˜ ì²« ë²ˆì§¸ PDF ì°¾ê¸°
        pdf_files = list(Path(FB21_PATH).rglob("*.pdf"))
        if not pdf_files:
            pytest.skip("PDF íŒŒì¼ ì—†ìŒ")

        pdf_path = str(pdf_files[0])
        result = matcher.match_pdf_to_topics(pdf_path)

        # ê²°ê³¼ êµ¬ì¡° í™•ì¸
        assert "pdf_file" in result
        assert "detected_domain" in result
        assert "extracted_keywords" in result
        assert "matched_topics" in result

        # í‚¤ì›Œë“œ ì¶”ì¶œ í™•ì¸
        assert len(result["extracted_keywords"]) > 0

        # ë„ë©”ì¸ ê°ì§€ í™•ì¸
        assert result["detected_domain"] in matcher.DOMAIN_PATTERNS or result["detected_domain"] == "ê¸°íƒ€"

        print(f"\nğŸ“„ PDF: {result['pdf_file']}")
        print(f"ğŸ¯ ë„ë©”ì¸: {result['detected_domain']}")
        print(f"ğŸ”‘ í‚¤ì›Œë“œ: {result['extracted_keywords'][:5]}")
        print(f"ğŸ“š ë§¤ì¹­ í† í”½:")
        for t in result['matched_topics'][:3]:
            print(f"  - {t['file_name']} ({t['domain']}): {t['similarity']:.3f}")

    @pytest.mark.skipif(
        not Path(FB21_PATH).exists(),
        reason="FB21 ê²½ë¡œì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŒ"
    )
    def test_scan_directory(self, matcher):
        """ë””ë ‰í† ë¦¬ ìŠ¤ìº” í…ŒìŠ¤íŠ¸."""
        results = matcher.scan_and_match_directory(FB21_PATH, max_pdfs=3)

        assert len(results) > 0

        # ê° ê²°ê³¼ì˜ êµ¬ì¡° í™•ì¸
        for result in results:
            if "error" not in result:
                assert "pdf_file" in result
                assert "matched_topics" in result

        print(f"\nğŸ“Š ìŠ¤ìº”í•œ PDF ìˆ˜: {len(results)}")


class TestPDFTopicMatcherAdvanced:
    """ê³ ê¸‰ PDF-í† í”½ ë§¤ì¹­ í…ŒìŠ¤íŠ¸."""

    @pytest.fixture
    def matcher_with_config(self, tmp_path):
        """ì„¤ì •ì´ í¬í•¨ëœ PDFTopicMatcher fixture."""
        # í…ŒìŠ¤íŠ¸ìš© ì„¤ì • íŒŒì¼ ìƒì„±
        config_dir = tmp_path / "config"
        config_dir.mkdir()

        # í…ŒìŠ¤íŠ¸ìš© ë™ì˜ì–´ íŒŒì¼
        synonyms_data = {
            "ë„¤íŠ¸ì›Œí¬": ["NW", "ë§", "network"],
            "TCP/IP": ["TCP IP", "TCPIP"],
        }

        import yaml
        synonyms_file = config_dir / "synonyms.yaml"
        with open(synonyms_file, "w", encoding="utf-8") as f:
            yaml.dump(synonyms_data, f, allow_unicode=True)

        # í…ŒìŠ¤íŠ¸ìš© ë¶ˆìš©ì–´ íŒŒì¼
        stopwords_data = {
            "korean_basic": ["ì´ë‹¤", "ìˆë‹¤", "í•˜ë‹¤"],
            "english_basic": ["the", "and", "is", "are"],
        }

        stopwords_file = config_dir / "stopwords.yaml"
        with open(stopwords_file, "w", encoding="utf-8") as f:
            yaml.dump(stopwords_data, f, allow_unicode=True)

        return PDFTopicMatcher(
            SAMPLE_JSON,
            config_dir=str(config_dir),
            use_synonyms=True,
            use_stopwords=True,
        )

    def test_matcher_with_custom_config(self, matcher_with_config):
        """ì‚¬ìš©ì ì„¤ì •ì„ ì‚¬ìš©í•œ ë§¤ì²˜ í…ŒìŠ¤íŠ¸."""
        # ì„¤ì •ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert matcher_with_config.keyword_extractor is not None
        assert matcher_with_config.keyword_extractor.use_synonyms is True
        assert matcher_with_config.keyword_extractor.use_stopwords is True

    def test_keyword_extraction_with_custom_synonyms(self, matcher_with_config):
        """ì‚¬ìš©ì ì •ì˜ ë™ì˜ì–´ë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸."""
        text = "NW ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤. ë§ ì—°ê²° ìƒíƒœë¥¼ ì ê²€í•©ë‹ˆë‹¤."

        keywords = matcher_with_config._extract_keywords(text)
        keyword_str = " ".join(keywords).lower()

        # ë™ì˜ì–´ í™•ì¥ í™•ì¸
        has_network = any(
            kw in keyword_str
            for kw in ["ë„¤íŠ¸ì›Œí¬", "network", "nw", "ë§"]
        )
        assert has_network
